download_status: UNINITIALIZED
experiment_date: '2024-07-25 22:38:02.712928'
framework: tf
gen_params:
  do_sample: true
  early_stopping: true
  length_penalty: -0.5
  max_new_tokens: 252
  min_new_tokens: 54
  num_beams: 3
  repetition_penalty: 1.2
  temperature: 0.45
  top_k: 100
  top_p: 0.85
hf_repo: AdaptLLM/medicine-chat
local: ''
model_params:
  device_map: cuda
  load_in_4bit: false
  load_in_8bit: false
  torch_dtype: bfloat16
name: Domain Adaptation of Large Language Models
properties:
  access_space:
  - local
  cost:
  - free in price
  - power consumption
  domain: medical
  predecessor: llama-7b
  size: '7'
  task: instruction following
revision: 0ddb624
weightpat: '*.safetensors'
