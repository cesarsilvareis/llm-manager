download_status: UNINITIALIZED
experiment_date: 09/03/2024
framework: tf
hf_repo: AdaptLLM/medicine-chat
local: ''
name: Domain Adaptation of Large Language Models
model_params:
  load_in_4bit: False
  load_in_8bit: False
gen_params:
  max_new_tokens: 512
  temperature: .65
  # top_k: [5, 50, 100]
  # top_p: [0.15, 0.5, 0.75]
  num_beams: 2
  repetition_penalty: [1.0, 1.5, 2.0]
  length_penalty: [-1.0, .0, 1.0]
properties:
  access_space:
  - local
  cost:
  - free in price
  - power consumption
  domain: medical
  predecessor: llama-7b
  size: '7'
  task: instruction following
revision: 0ddb624
weightpat: '*.safetensors'
